{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-uMX1aW8NyX",
        "outputId": "60d24297-bf6c-418d-ff64-cb41c9447f44"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw7ZG9XyysF5",
        "outputId": "aca320a8-a02c-46d2-a8de-09e70ed49b39"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrF9f7GNyu-r"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from mtcnn import MTCNN\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "detector = MTCNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQC1tSjwz4Tv"
      },
      "outputs": [],
      "source": [
        "cv2.setUseOptimized(True)\n",
        "cv2.setNumThreads(4)\n",
        "cv2.ocl.setUseOpenCL(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oirVtuAsy2c-"
      },
      "outputs": [],
      "source": [
        "TARGET_SIZE = (300, 300)\n",
        "\n",
        "def test_preprocess_video(video_path):\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "\n",
        "        results = detector.detect_faces(frame)\n",
        "\n",
        "        if results:\n",
        "            x, y, w, h = results[0]['box']\n",
        "            face = frame[y:y+h, x:x+w]\n",
        "\n",
        "\n",
        "            if len(face.shape) == 2:\n",
        "                face = cv2.cvtColor(face, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "            face = cv2.resize(face, TARGET_SIZE)\n",
        "\n",
        "            frames.append(face)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HM7Oylbze7v",
        "outputId": "da467a37-e9d1-4b52-fd45-ea31b5f59941"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Flatten, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "DATA_FOLDER = \"gdrive/My Drive/ColabDrive/deepfake-detection-challenge/train_colab_videos/\"\n",
        "MODEL_FILE = \"my_model_one.h5\"\n",
        "\n",
        "test_model = load_model(os.path.join(DATA_FOLDER, MODEL_FILE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcfER9d7zGXG",
        "outputId": "ce559819-41e3-420a-b260-cbd61f6301b3"
      },
      "outputs": [],
      "source": [
        "test_video_path = 'gdrive/My Drive/ColabDrive/deepfake-detection-challenge/train_sample_videos/aagfhgtpmv.mp4'\n",
        "\n",
        "test_frames = test_preprocess_video(test_video_path)\n",
        "test_data = np.array(test_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U5hLcaHzbFZ",
        "outputId": "ecad75e8-1084-47cb-e715-df52dcc48cfe"
      },
      "outputs": [],
      "source": [
        "frame_predictions_list = test_model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLoXy2f_KsWz",
        "outputId": "bb47e7f0-cd78-4f52-d538-76eea0a30abd"
      },
      "outputs": [],
      "source": [
        "real_frames = 0\n",
        "fake_frames = 0\n",
        "\n",
        "for frame_predictions in frame_predictions_list:\n",
        "    frame_real = 0\n",
        "    frame_fake = 0\n",
        "\n",
        "    for prediction in frame_predictions:\n",
        "        if prediction[0] > 0.5:\n",
        "            frame_real += 1\n",
        "        else:\n",
        "            frame_fake += 1\n",
        "\n",
        "    if frame_real > frame_fake:\n",
        "        real_frames += 1\n",
        "    else:\n",
        "        fake_frames += 1\n",
        "\n",
        "if real_frames > fake_frames:\n",
        "    video_category = \"REAL\"\n",
        "else:\n",
        "    video_category = \"FAKE\"\n",
        "\n",
        "print(\"Video Category:\", video_category)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
