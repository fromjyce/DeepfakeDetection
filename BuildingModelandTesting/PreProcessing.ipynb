{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4Ys2Azu3xUg",
        "outputId": "59d2b96a-a755-43e3-a927-472daa7d0d0c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v50-_DdMyOs",
        "outputId": "2ed8f9e2-ad87-4618-c8b4-4f7311b2dc26"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install mtcnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpmmwxaKMvvF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from mtcnn import MTCNN\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import tensorflow as tf\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "zf = ZipFile('train_sample_videos-20240524T065131Z-001.zip', 'r')\n",
        "zf.extractall('train_sample_videos')\n",
        "zf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyXr7jHE62qA",
        "outputId": "e674b0b4-f7b6-47dc-e7e6-5ea39f4bc0e2"
      },
      "outputs": [],
      "source": [
        "DATA_FOLDER = \"train_sample_videos/\"\n",
        "TRAIN_FOLDER = \"train_sample_videos\"\n",
        "\n",
        "video_files = [file for file in os.listdir(os.path.join(DATA_FOLDER, TRAIN_COLAB_FOLDER)) if file.endswith('.mp4')]\n",
        "print(video_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUGpQ1vCNWNI"
      },
      "outputs": [],
      "source": [
        "cv2.setUseOptimized(True)\n",
        "cv2.setNumThreads(4)\n",
        "cv2.ocl.setUseOpenCL(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bktzkwOwGgMT"
      },
      "outputs": [],
      "source": [
        "TARGET_SIZE = (300, 300)\n",
        "FRAME_SKIP = 5\n",
        "NUM_WORKERS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMXyy4N1NAv4"
      },
      "outputs": [],
      "source": [
        "detector = MTCNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VQdBdlncFSb"
      },
      "outputs": [],
      "source": [
        "def preprocess_video(video_path, frame_skip):\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % frame_skip == 0:\n",
        "            results = detector.detect_faces(frame)\n",
        "            if results:\n",
        "                x, y, w, h = results[0]['box']\n",
        "                face = frame[y:y+h, x:x+w]\n",
        "                if len(face.shape) == 2:\n",
        "                    face = cv2.cvtColor(face, cv2.COLOR_GRAY2BGR)\n",
        "                face = cv2.resize(face, TARGET_SIZE)\n",
        "                frames.append(face)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcSR7jY4PKGB"
      },
      "outputs": [],
      "source": [
        "json_file_path = os.path.join(DATA_FOLDER, TRAIN_FOLDER, \"metadata.json\")\n",
        "with open(json_file_path, \"r\") as json_file:\n",
        "    metadata = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1X6McydPYZ_"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTZqOWZMTgcI",
        "outputId": "3d8417be-1e2c-4921-bf34-05ea06f0990f"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "label_mapping = {'FAKE': 0, 'REAL': 1}\n",
        "\n",
        "\n",
        "def process_video(video_path, video_file):\n",
        "    info = metadata[video_file]\n",
        "    frames = preprocess_video(video_path)\n",
        "    data.extend(frames)\n",
        "    video_label = info[\"label\"]\n",
        "    video_label_sequence = [label_mapping[video_label]] * len(frames)\n",
        "    labels.extend([video_label_sequence] * len(frames))\n",
        "\n",
        "\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(DATA_FOLDER, TRAIN_COLAB_FOLDER, video_file)\n",
        "        executor.submit(process_video, video_path, video_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoaAR_-Zvkx5",
        "outputId": "6c16987c-5909-4bb5-c84a-76cd1bc95eb7"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "max_sequence_length = 8\n",
        "labels = [sequence[:max_sequence_length] if len(sequence) >= max_sequence_length else sequence + [0] * (max_sequence_length - len(sequence)) for sequence in labels]\n",
        "\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "print(\"Data shape:\", data.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "\n",
        "num_classes = len(label_mapping)\n",
        "one_hot_labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "\n",
        "print(\"One-hot Labels shape:\", one_hot_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJOfVAz0xRli",
        "outputId": "d075ace1-977e-46b5-8c93-1205938133db"
      },
      "outputs": [],
      "source": [
        "print(len(data), len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, one_hot_labels, test_size=0.2, random_state=42)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
